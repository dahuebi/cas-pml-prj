{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, os.path.join(BASEDIR, \"coinmarketcap-scraper\"))\n",
    "sys.path.insert(0, os.path.join(BASEDIR, \"coinmarketcap-history\"))\n",
    "\n",
    "BASEDIR = \"\"\n",
    "CACHEDIR = os.path.join(BASEDIR, \"cache\")\n",
    "COINS = \"coins\"\n",
    "TOKENS = \"tokens\"\n",
    "\n",
    "if not os.path.exists(CACHEDIR):\n",
    "    os.makedirs(CACHEDIR)\n",
    "def getPath(filename):\n",
    "    return os.path.join(CACHEDIR, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper for coinmarketcap-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coinmarketcap\n",
    "def scrapeCoinList():\n",
    "    \"\"\"Scrape coin list.\"\"\"\n",
    "    coinmarketcap.lastReqTime = None\n",
    "    html = coinmarketcap.requestList('coins', 'all')\n",
    "    data = coinmarketcap.parseList(html, 'currencies')\n",
    "    return data\n",
    "\n",
    "\n",
    "def scrapeTokenList():\n",
    "    \"\"\"Scrape token list.\"\"\"\n",
    "    coinmarketcap.lastReqTime = None\n",
    "    html = coinmarketcap.requestList('tokens', 'all')\n",
    "    data = coinmarketcap.parseList(html, 'assets')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper around coinmarketcap_usd_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coinmarketcap_usd_history\n",
    "def downloadHistoricalData(currency, startDate, endDate):\n",
    "    # date format required by coinmarketcap_usd_history\n",
    "    def historicalDate(date):\n",
    "        if isinstance(date, datetime.datetime):\n",
    "            return date.strftime(\"%Y%m%d\")\n",
    "        return date\n",
    "    startDate, endDate = historicalDate(startDate), historicalDate(endDate)\n",
    "    print(currency, startDate, endDate)\n",
    "    html = coinmarketcap_usd_history.download_data(currency, startDate, endDate)\n",
    "    header, rows = coinmarketcap_usd_history.extract_data(html)\n",
    "    return header, rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for scrape currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n",
      "546\n"
     ]
    }
   ],
   "source": [
    "def readCachedCurrenciesFile(filename):\n",
    "    path = getPath(filename)\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    with codecs.open(path, \"r\", encoding=\"UTF-8\") as fp:\n",
    "        try:\n",
    "            return json.load(fp)\n",
    "        except json.JSONDecodeError:\n",
    "            return []\n",
    "\n",
    "def writeCachedCurrenciesFile(filename, data):\n",
    "    path = getPath(filename)\n",
    "    with codecs.open(path, \"w\", encoding=\"UTF-8\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "      \n",
    "def scrapeCurrencies():\n",
    "    # coins\n",
    "    coinsFilename = \"coins.txt\"\n",
    "    coins = readCachedCurrenciesFile(coinsFilename)\n",
    "    if not coins:\n",
    "        coins = scrapeCoinList()\n",
    "        writeCachedCurrenciesFile(coinsFilename, coins)\n",
    "    print(len(coins))\n",
    "    \n",
    "    # tokens\n",
    "    tokensFilename = \"tokens.txt\"\n",
    "    tokens = readCachedCurrenciesFile(tokensFilename)\n",
    "    if not tokens:\n",
    "        tokens = scrapeTokenList()\n",
    "        writeCachedCurrenciesFile(tokensFilename, tokens)\n",
    "    print(len(tokens))\n",
    "    return coins, tokens\n",
    "   \n",
    "coins, tokens = scrapeCurrencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethereum 20010102 20180121\n",
      "ripple 20010102 20180121\n",
      "bitcoin-cash 20010102 20180121\n",
      "cardano 20010102 20180121\n",
      "litecoin 20010102 20180121\n",
      "nem 20010102 20180121\n",
      "neo 20010102 20180121\n",
      "stellar 20010102 20180121\n",
      "iota 20010102 20180121\n",
      "dash 20010102 20180121\n",
      "monero 20010102 20180121\n",
      "bitcoin-gold 20010102 20180121\n",
      "qtum 20010102 20180121\n",
      "ethereum-classic 20010102 20180121\n",
      "lisk 20010102 20180121\n",
      "raiblocks 20010102 20180121\n",
      "vechain 20010102 20180121\n",
      "verge 20010102 20180121\n",
      "zcash 20010102 20180121\n",
      "siacoin 20010102 20180121\n",
      "stratis 20010102 20180121\n",
      "bytecoin-bcn 20010102 20180121\n",
      "steem 20010102 20180121\n",
      "bitshares 20010102 20180121\n",
      "kucoin-shares 20010102 20180121\n",
      "waves 20010102 20180121\n",
      "dogecoin 20010102 20180121\n",
      "electroneum 20010102 20180121\n",
      "komodo 20010102 20180121\n",
      "decred 20010102 20180121\n",
      "ark 20010102 20180121\n",
      "digibyte 20010102 20180121\n",
      "hshare 20010102 20180121\n",
      "smartcash 20010102 20180121\n",
      "pivx 20010102 20180121\n",
      "byteball 20010102 20180121\n",
      "zclassic 20010102 20180121\n",
      "factom 20010102 20180121\n",
      "monacoin 20010102 20180121\n",
      "reddcoin 20010102 20180121\n",
      "syscoin 20010102 20180121\n",
      "nexus 20010102 20180121\n",
      "neblio 20010102 20180121\n",
      "experience-points 20010102 20180121\n",
      "emercoin 20010102 20180121\n",
      "zcoin 20010102 20180121\n",
      "bitcore 20010102 20180121\n",
      "gxshares 20010102 20180121\n",
      "nxt 20010102 20180121\n",
      "bitcoindark 20010102 20180121\n",
      "cryptonex 20010102 20180121\n",
      "particl 20010102 20180121\n",
      "gamecredits 20010102 20180121\n",
      "paccoin 20010102 20180121\n",
      "digitalnote 20010102 20180121\n",
      "skycoin 20010102 20180121\n",
      "vertcoin 20010102 20180121\n",
      "bridgecoin 20010102 20180121\n",
      "nav-coin 20010102 20180121\n"
     ]
    }
   ],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(\n",
    "#    level=logging.ERROR,\n",
    "#    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "#    datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "def loadCurrencyFromCsv(currency):\n",
    "    path = getPath(\"{}.csv\".format(currency))\n",
    "    header, data = [], []\n",
    "    if not os.path.exists(path):\n",
    "        return header, data\n",
    "    with codecs.open(path, \"r\", encoding=\"UTF-8\") as fp:\n",
    "        reader = csv.reader(fp)\n",
    "        try:\n",
    "            header = next(reader)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        data = list(reader)\n",
    "    return header, data\n",
    "\n",
    "def saveCurrencyToCsv(currency, header, data):\n",
    "    path = getPath(\"{}.csv\".format(currency))\n",
    "    newData = sorted(data, key=lambda row: row[0], reverse=True)\n",
    "    with codecs.open(path, \"w\", encoding=\"UTF-8\") as fp:\n",
    "        writer = csv.writer(fp, quoting=csv.QUOTE_NONE)\n",
    "        [writer.writerow(row) for row in itertools.chain([header], newData)]\n",
    "\n",
    "\n",
    "def downloadCurrency(currency):\n",
    "    parseDate = lambda s: datetime.datetime.strptime(s, \"%Y-%m-%d\")\n",
    "    slug = currency[\"slug\"]\n",
    "    # set default startTime\n",
    "    startDate = parseDate(\"2001-01-01\")\n",
    "    # get current UTC datetime\n",
    "    endDate = datetime.datetime.utcnow()\n",
    "    # floor to day\n",
    "    endDate = endDate.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "   \n",
    "    # try to load data from cache\n",
    "    header, data = loadCurrencyFromCsv(slug)\n",
    "    for row in data:\n",
    "        startDate = max(startDate, parseDate(row[0]))\n",
    "    # increment one date\n",
    "    startDate += datetime.timedelta(days=1)\n",
    "    if startDate >= endDate:\n",
    "        return\n",
    "    \n",
    "    header, newData= downloadHistoricalData(slug, startDate, endDate)\n",
    "    if not newData:\n",
    "        return\n",
    "    # remove average\n",
    "    header = header[:-1]\n",
    "    for row in newData:\n",
    "        row = row[:-1] # remove Average\n",
    "        # parse date from module\n",
    "        row[0] = datetime.datetime.strptime(row[0], \"%b %d %Y\").strftime(\"%Y-%m-%d\")\n",
    "        data.append(row)\n",
    "    saveCurrencyToCsv(slug, header, data)\n",
    "    \n",
    "for currency in itertools.chain(coins, tokens):\n",
    "    downloadCurrency(currency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
